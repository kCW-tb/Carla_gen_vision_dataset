# í´ë˜ìŠ¤ í™•ì¸í•˜ëŠ” ì½”ë“œ

import sys
import glob
import numpy as np
import cv2
from PIL import Image
import os
import time

# CARLA Python API ê²½ë¡œ ì„¤ì •
try:
    sys.path.append(glob.glob('../carla/dist/carla-*%d.%d-%s.egg' % (
        sys.version_info.major,
        sys.version_info.minor,
        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])
except IndexError:
    pass

import carla

# ===========================
# ì„¤ì •
# ===========================
# carla í´ë˜ìŠ¤
# 14ë²ˆ ì°¨ëŸ‰
# 15ë²ˆ íŠ¸ëŸ­
# 18ë²ˆ ì˜¤í† ë°”ì´
# 20ë²ˆ ì¡ë™ì‚¬ë‹ˆ ê±´ë¬¼..?
# 21ë²ˆ ì¡ë™ì‚¬ë‹ˆ
# LANE_CLASS_ID = 24  # ì°¨ì„  ê²½ê³„ì„  class (Carla semantic segmentation ê¸°ì¤€)
# 1ë²ˆ ì°¨ë„
# 2ë²ˆ ì¸ë„
# 3ë²ˆ ë°°ê²½
# 6ë²ˆ ê°€ë¡œë“±
# 7ë²ˆ ì‹ í˜¸ë“± ì—‘í„°
# 8ë²ˆ TrafficSign
# 12ë²ˆ ì‚¬ëŒ.
LANE_CLASS_ID = 24 # ì°¨ì„  ê²½ê³„ì„  class (Carla semantic segmentation ê¸°ì¤€)
SAVE_DURATION = 120  # ì €ì¥í•  ì‹œê°„(ì´ˆ)
IMAGE_WIDTH = 1280
IMAGE_HEIGHT = 720
# OUTPUT_DIR = 'lane_dataset'  # ì €ì¥ ê²½ë¡œ
OUTPUT_DIR = 'drivable_dataset'  # ì €ì¥ ê²½ë¡œ

# ===========================
# ì„¼ì„œ ì„¤ì •
# ===========================
def spawn_segmentation_camera(world, vehicle):
    bp_lib = world.get_blueprint_library()
    cam_bp = bp_lib.find("sensor.camera.semantic_segmentation")
    cam_bp.set_attribute("image_size_x", str(IMAGE_WIDTH))
    cam_bp.set_attribute("image_size_y", str(IMAGE_HEIGHT))
    cam_bp.set_attribute("fov", "90")
    cam_bp.set_attribute("sensor_tick", "0.2")  # 0.2ì´ˆë§ˆë‹¤ í”„ë ˆì„ ìƒì„± (5fps)

    transform = carla.Transform(carla.Location(x=1.5, z=2.4))
    camera = world.spawn_actor(cam_bp, transform, attach_to=vehicle)
    return camera

def spawn_traffic(world, num_vehicles=20):
    blueprint_library = world.get_blueprint_library()
    vehicle_blueprints = blueprint_library.filter('vehicle.*')

    spawn_points = world.get_map().get_spawn_points()
    if len(spawn_points) < num_vehicles:
        num_vehicles = len(spawn_points)

    vehicles = []
    for i in range(num_vehicles):
        bp = np.random.choice(vehicle_blueprints)
        transform = spawn_points[i]
        npc = world.try_spawn_actor(bp, transform)
        if npc is not None:
            npc.set_autopilot(True)
            vehicles.append(npc)
    print(f"ğŸš— ì´ {len(vehicles)} ëŒ€ì˜ AI ì°¨ëŸ‰ì´ ìŠ¤í°ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return vehicles
# ===========================
# YOLO Segmentation ì €ì¥
# ===========================
def process_and_save(image, frame_id):
    # Carlaì—ì„œ ë°›ì€ segmentation ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
    array = np.frombuffer(image.raw_data, dtype=np.uint8)
    array = array.reshape((IMAGE_HEIGHT, IMAGE_WIDTH, 4))[:, :, :3]
    segmentation_mask = array[:, :, 2]  # Red ì±„ë„ì´ class ID


    # ì°¨ì„ (RoadLines)ë§Œ ì¶”ì¶œ
    # mask = (segmentation_mask == LANE_CLASS_ID).astype(np.uint8) * 255
    # ì°¨ì„  + ë„ë¡œ ì¶”ì¶œ
    INCLUDED_CLASSES = [1, 24]
    mask = np.isin(segmentation_mask, INCLUDED_CLASSES).astype(np.uint8) * 255

    # ìœ¤ê³½ì„  ì°¾ê¸°
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    label_lines = []
    for contour in contours:
        if len(contour) < 6:
            continue  # ë„ˆë¬´ ì‘ì€ contourëŠ” ë¬´ì‹œ
        # ì •ê·œí™” (YOLO í¬ë§·: 0~1 ì¢Œí‘œ)
        normalized = [(pt[0][0] / IMAGE_WIDTH, pt[0][1] / IMAGE_HEIGHT) for pt in contour]
        flattened = ' '.join([f"{x:.6f} {y:.6f}" for x, y in normalized])
        label_lines.append(f"0 {flattened}")  # class 0 (lane)

    # ì´ë¯¸ì§€ ì €ì¥ (RGB ë³€í™˜)
    rgb_image = Image.fromarray(array).convert("RGB")
    img_path = os.path.join(OUTPUT_DIR, 'images', f"{frame_id:06d}.jpg")
    label_path = os.path.join(OUTPUT_DIR, 'labels', f"{frame_id:06d}.txt")

    rgb_image.save(img_path)

    with open(label_path, 'w') as f:
        f.write('\n'.join(label_lines))
    
    # ------------------------
    # ì‹œê°í™”: ì›ë³¸ ì´ë¯¸ì§€ ìœ„ì— ì°¨ì„  ë§ˆìŠ¤í¬ ë°˜íˆ¬ëª… ì˜¤ë²„ë ˆì´
    # ------------------------
    # OpenCVìš© BGR ì´ë¯¸ì§€ë¡œ ë³€í™˜
    bgr_image = cv2.cvtColor(np.array(rgb_image), cv2.COLOR_RGB2BGR)

    # ë§ˆìŠ¤í¬ ì»¬ëŸ¬ (ë…¹ìƒ‰)
    color_mask = np.zeros_like(bgr_image)
    color_mask[mask == 255] = (0, 255, 0)  # ë…¹ìƒ‰

    # ë°˜íˆ¬ëª… í•©ì„± (ì›ë³¸ 70%, ë§ˆìŠ¤í¬ 30%)
    overlayed = cv2.addWeighted(bgr_image, 0.7, color_mask, 0.3, 0)

    # OpenCV ìœˆë„ìš°ì— ì¶œë ¥
    cv2.imshow('Segmentation Overlay', overlayed)
    cv2.waitKey(1)  # 1ms ëŒ€ê¸° (í•„ìˆ˜, ê·¸ë˜ì•¼ ì´ë¯¸ì§€ê°€ ì¶œë ¥ë¨)



# ===========================
# ë©”ì¸ ì‹¤í–‰
# ===========================
def main():
    # Carla í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
    client = carla.Client('localhost', 2000)
    client.set_timeout(5.0)
    world = client.get_world()

    # ì°¨ëŸ‰ ì„ íƒ
    vehicles = world.get_actors().filter('vehicle.*')
    if not vehicles:
        print("ğŸš— ì°¨ëŸ‰ì´ ì—†ìŠµë‹ˆë‹¤. í•˜ë‚˜ ìŠ¤í°í•´ ì£¼ì„¸ìš”.")
        return
    ego_vehicle = vehicles[0]

    # ì¶”ê°€: íŠ¸ë˜í”½ ìƒì„±
    traffic_vehicles = spawn_traffic(world, num_vehicles=30)

    # ì €ì¥ í´ë” ìƒì„±
    os.makedirs(os.path.join(OUTPUT_DIR, 'images'), exist_ok=True)
    os.makedirs(os.path.join(OUTPUT_DIR, 'labels'), exist_ok=True)

    # ì„¼ì„œ ì„¤ì •
    camera = spawn_segmentation_camera(world, ego_vehicle)

    # í”„ë ˆì„ ì €ì¥ ë£¨í”„
    frame = {'id': 0}
    def callback(image):
        process_and_save(image, frame['id'])
        print(f"ğŸ“¸ ì €ì¥ë¨: frame {frame['id']}")
        frame['id'] += 1

    camera.listen(callback)

    try:
        print("ğŸŸ¢ ì°¨ì„  ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        time.sleep(SAVE_DURATION)
    finally:
        camera.stop()
        camera.destroy()
        # ì¶”ê°€: íŠ¸ë˜í”½ ì°¨ëŸ‰ ì •ë¦¬
        for v in traffic_vehicles:
            v.destroy()
        print("ğŸ›‘ ìˆ˜ì§‘ ì¢…ë£Œ ë° ëª¨ë“  ì°¨ëŸ‰ ì œê±° ì™„ë£Œ.")


if __name__ == '__main__':
    main()
