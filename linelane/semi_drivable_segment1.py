#ì£¼í–‰ê°€ëŠ¥ì˜ì—­ ì¶”ì¶œí•˜ëŠ” ì½”ë“œ.


import carla
import numpy as np
import cv2
import os
import argparse
import time
from queue import Queue

# ==============================================================================
# -- ìƒìˆ˜ ì •ì˜ (Constants)
# ==============================================================================

# ì£¼í–‰ ê°€ëŠ¥ ì˜ì—­ì„ ì˜ë¯¸ì— ë”°ë¼ ë‹¤ë¥¸ í´ë˜ìŠ¤ë¡œ ì •ì˜
CLASS_VALUES = {
    "unlabeled": 0,       # ë¼ë²¨ë§ë˜ì§€ ì•Šì€ ì˜ì—­
    "current_lane": 1,    # í˜„ì¬ ì£¼í–‰ ì°¨ì„ 
    "lane_change": 2,     # ë³€ê²½ ê°€ëŠ¥í•œ ì¸ì ‘ ì°¨ì„ 
    "intersection": 3     # êµì°¨ë¡œ ë‚´ ì£¼í–‰ ê°€ëŠ¥ ê²½ë¡œ
}

# ê° í´ë˜ìŠ¤ë¥¼ ì‹œê°í™”í•˜ê¸° ìœ„í•œ ìƒ‰ìƒ ì •ì˜ (BGR í¬ë§·)
COLOR_MAP = {
    0: [0, 0, 0],         # unlabeled: Black
    1: [255, 0, 0],       # current_lane: Blue
    2: [0, 255, 0],       # lane_change: Green
    3: [0, 0, 255]        # intersection: Red
}

# ê¸°ë³¸ ë„ë¡œ/ì°¨ì„ ìœ¼ë¡œ ì¸ì‹í•  ì‹œë§¨í‹± íƒœê·¸ ID
# DRIVABLE_SEG_TAGS = {7, 6} # CARLA 0.9.x ê¸°ì¤€
DRIVABLE_SEG_TAGS = {1, 24}  # ì‚¬ìš©ì ì œê³µ ê¸°ì¤€

# ì´ë¯¸ì§€ í•´ìƒë„ ë° ì¹´ë©”ë¼ ì„¤ì •
IMAGE_WIDTH, IMAGE_HEIGHT, CAMERA_FOV = 1280, 720, 90
DATA_SAVE_INTERVAL = 1.0 # ë°ì´í„° ì €ì¥ ê°„ê²© (ì´ˆ)
OUTPUT_DIR = 'drivable_multiclass_dataset'

# ==============================================================================
# -- ë„ìš°ë¯¸ í•¨ìˆ˜ (Helper Functions)
# ==============================================================================

def ensure_dir(directory):
    if not os.path.exists(directory): os.makedirs(directory)

def build_projection_matrix(w, h, fov):
    focal = w / (2.0 * np.tan(fov * np.pi / 360.0))
    K = np.identity(3)
    K[0, 0] = K[1, 1] = focal
    K[0, 2], K[1, 2] = w / 2.0, h / 2.0
    return K

def get_image_point(loc, K, w2c):
    point = np.array([loc.x, loc.y, loc.z, 1])
    point_camera = np.dot(w2c, point)
    point_camera = np.array([point_camera[1], -point_camera[2], point_camera[0]])
    if point_camera[2] < 0.01: return None
    point_img = np.dot(K, point_camera)
    point_img[0] /= point_img[2]; point_img[1] /= point_img[2]
    return (int(point_img[0]), int(point_img[1]))

def create_colormap(mask):
    colormap = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)
    for value, color in COLOR_MAP.items():
        colormap[mask == value] = color
    return colormap

# ==============================================================================
# -- ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ==============================================================================

def game_loop(args):
    client, world, actor_list = None, None, []
    
    try:
        # 1. CARLA ì„œë²„ ì—°ê²°
        client = carla.Client(args.host, args.port)
        client.set_timeout(10.0)
        world = client.get_world()
        carla_map = world.get_map()
        print(f"í˜„ì¬ ë§µ '{carla_map.name.split('/')[-1]}'ì— ì—°ê²°í–ˆìŠµë‹ˆë‹¤.")
        
        # 2. ë°ì´í„° ì €ì¥ í´ë” ìƒì„±
        ensure_dir(os.path.join(OUTPUT_DIR, 'image'))
        ensure_dir(os.path.join(OUTPUT_DIR, 'label_mask'))
        ensure_dir(os.path.join(OUTPUT_DIR, 'label_txt'))
        ensure_dir(os.path.join(OUTPUT_DIR, 'colormap'))

        # 3. Ego ì°¨ëŸ‰ ì°¾ê¸°
        vehicle = None
        for _ in range(15):
            actors = world.get_actors().filter('vehicle.*')
            for actor in actors:
                if actor.attributes.get('role_name') == args.role_name:
                    vehicle = actor; break
            if vehicle: break
            print(f"'{args.role_name}' ì°¨ëŸ‰ì„ ì°¾ëŠ” ì¤‘...")
            time.sleep(1)
        
        if not vehicle:
            print(f"ì˜¤ë¥˜: '{args.role_name}' ì°¨ëŸ‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. manual_control.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return
        print(f"Ego ì°¨ëŸ‰ (ID: {vehicle.id})ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤. ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

        # 4. ë™ê¸°í™”ëœ ì„¼ì„œ ì„¤ì¹˜
        sensor_queue = Queue()
        blueprint_library = world.get_blueprint_library()
        cam_transform = carla.Transform(carla.Location(x=1.5, z=2.4))

        # RGB ì¹´ë©”ë¼
        rgb_bp = blueprint_library.find('sensor.camera.rgb')
        rgb_bp.set_attribute('image_size_x', str(IMAGE_WIDTH)); rgb_bp.set_attribute('image_size_y', str(IMAGE_HEIGHT))
        rgb_cam = world.spawn_actor(rgb_bp, cam_transform, attach_to=vehicle)
        actor_list.append(rgb_cam)
        rgb_cam.listen(lambda data: sensor_queue.put(('rgb', data)))

        # ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¹´ë©”ë¼
        seg_bp = blueprint_library.find('sensor.camera.semantic_segmentation')
        seg_bp.set_attribute('image_size_x', str(IMAGE_WIDTH)); seg_bp.set_attribute('image_size_y', str(IMAGE_HEIGHT))
        seg_cam = world.spawn_actor(seg_bp, cam_transform, attach_to=vehicle)
        actor_list.append(seg_cam)
        seg_cam.listen(lambda data: sensor_queue.put(('seg', data)))
        
        # 5. ë™ê¸° ëª¨ë“œ ì„¤ì • ë° ë°ì´í„° ìˆ˜ì§‘ ë£¨í”„
        original_settings = world.get_settings()
        settings = world.get_settings()
        settings.synchronous_mode = True; settings.fixed_delta_seconds = 0.05
        world.apply_settings(settings)

        last_saved_time = 0

        while True:
            world.tick()
            try:
                s_data = [sensor_queue.get(True, 1.0) for _ in range(2)]
            except Exception: continue

            s_data_dict = {item[0]: item[1] for item in s_data}
            if not ('rgb' in s_data_dict and 'seg' in s_data_dict) or \
               s_data_dict['rgb'].frame != s_data_dict['seg'].frame:
                continue

            rgb_image = s_data_dict['rgb']
            if rgb_image.timestamp - last_saved_time < DATA_SAVE_INTERVAL:
                continue
            
            last_saved_time = rgb_image.timestamp
            frame_id = rgb_image.frame

            # --- Waypoint ê¸°ë°˜ ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¼ë²¨ë§ ë¡œì§ ---
            waypoint = carla_map.get_waypoint(vehicle.get_location(), project_to_road=True)
            drivable_lanes_waypoints = []
            
            if waypoint.is_junction:
                # êµì°¨ë¡œ: ê°€ëŠ¥í•œ ëª¨ë“  ë‹¤ìŒ ê²½ë¡œë¥¼ "intersection" í´ë˜ìŠ¤ë¡œ ì¶”ê°€
                next_waypoints = waypoint.next(2.0)
                for w in next_waypoints:
                    # ê° ê²½ë¡œë¥¼ 15m ì•ê¹Œì§€ ì¶”ì 
                    lane_wps = w.next_until_lane_end(15.0)
                    drivable_lanes_waypoints.append({"waypoints": lane_wps, "class": "intersection"})
            else:
                # ì¼ë°˜ ë„ë¡œ: í˜„ì¬ ì°¨ì„ , ë³€ê²½ ê°€ëŠ¥ ì°¨ì„  íƒìƒ‰
                # 1. í˜„ì¬ ì°¨ì„  ("current_lane")
                drivable_lanes_waypoints.append({"waypoints": waypoint.next_until_lane_end(30.0), "class": "current_lane"})
                # 2. ìš°ì¸¡ ë³€ê²½ ê°€ëŠ¥ ì°¨ì„  ("lane_change")
                if waypoint.lane_change & carla.LaneChange.Right:
                    right_wp = waypoint.get_right_lane()
                    if right_wp and right_wp.lane_type == carla.LaneType.Driving:
                        drivable_lanes_waypoints.append({"waypoints": right_wp.next_until_lane_end(30.0), "class": "lane_change"})
                # 3. ì¢Œì¸¡ ë³€ê²½ ê°€ëŠ¥ ì°¨ì„  ("lane_change")
                if waypoint.lane_change & carla.LaneChange.Left:
                    left_wp = waypoint.get_left_lane()
                    if left_wp and left_wp.lane_type == carla.LaneType.Driving:
                        drivable_lanes_waypoints.append({"waypoints": left_wp.next_until_lane_end(30.0), "class": "lane_change"})
            
            # --- 3D Waypointë¥¼ 2D í´ë¦¬ê³¤ìœ¼ë¡œ ë³€í™˜ ---
            K = build_projection_matrix(IMAGE_WIDTH, IMAGE_HEIGHT, CAMERA_FOV)
            w2c = np.array(rgb_cam.get_transform().get_inverse_matrix())
            polygons_2d = []

            for lane in drivable_lanes_waypoints:
                lane_polygon_2d = []
                # Waypoint listê°€ ë¹„ì–´ìˆì§€ ì•Šì€ì§€ í™•ì¸
                if not lane["waypoints"]: continue
                for wp in lane["waypoints"]:
                    half_width, r_vec = wp.lane_width / 2.0, wp.transform.get_right_vector()
                    p_left = wp.transform.location - r_vec * half_width
                    p_right = wp.transform.location + r_vec * half_width
                    
                    pt_left, pt_right = get_image_point(p_left, K, w2c), get_image_point(p_right, K, w2c)
                    if pt_left and pt_right:
                        lane_polygon_2d.insert(0, pt_left)
                        lane_polygon_2d.append(pt_right)
                
                if len(lane_polygon_2d) > 2:
                    polygons_2d.append({"polygon": np.array(lane_polygon_2d, dtype=np.int32), "class": lane["class"]})
            
            # --- ë¼ë²¨ ë§ˆìŠ¤í¬ ìƒì„± ë° ë°ì´í„° ì €ì¥ ---
            label_mask = np.zeros((IMAGE_HEIGHT, IMAGE_WIDTH), dtype=np.uint8)
            # ìš°ì„ ìˆœìœ„ê°€ ë‚®ì€ ìˆœì„œë¶€í„° í´ë¦¬ê³¤ì„ ê·¸ë¦¼ (êµì°¨ë¡œê°€ ì¼ë°˜ ì°¨ì„ ì„ ë®ì–´ì“¸ ìˆ˜ ìˆë„ë¡)
            sorted_polygons = sorted(polygons_2d, key=lambda p: CLASS_VALUES[p['class']])
            
            for poly_info in sorted_polygons:
                class_value = CLASS_VALUES[poly_info["class"]]
                cv2.fillPoly(label_mask, [poly_info["polygon"]], class_value)

            filename = f"{frame_id:06d}"
            # 1. ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥
            rgb_image.save_to_disk(os.path.join(OUTPUT_DIR, 'image', f"{filename}.png"))
            # 2. ë¼ë²¨ ë§ˆìŠ¤í¬ ì €ì¥ (ê° í”½ì…€ê°’ì´ í´ë˜ìŠ¤ ID)
            cv2.imwrite(os.path.join(OUTPUT_DIR, 'label_mask', f"{filename}.png"), label_mask)
            # 3. í…ìŠ¤íŠ¸ ë¼ë²¨ ì €ì¥
            with open(os.path.join(OUTPUT_DIR, 'label_txt', f"{filename}.txt"), "w") as f:
                for poly_info in polygons_2d:
                    coords = " ".join([f"{p[0]},{p[1]}" for p in poly_info["polygon"]])
                    f.write(f"{poly_info['class']}:{coords}\n")
            # 4. ì»¬ëŸ¬ë§µ ì €ì¥ (ì‹œê°í™”ìš©)
            colormap_image = create_colormap(label_mask)
            cv2.imwrite(os.path.join(OUTPUT_DIR, 'colormap', f"{filename}.png"), colormap_image)

            print(f"ğŸ“¸ í”„ë ˆì„ {frame_id} ë°ì´í„° ì €ì¥ ì™„ë£Œ")
            cv2.imshow('Multi-Class Colormap', colormap_image)
            cv2.waitKey(1)

    finally:
        print("\nğŸ›‘ ë°ì´í„° ìˆ˜ì§‘ì„ ì¢…ë£Œí•˜ê³  í™˜ê²½ì„ ì •ë¦¬í•©ë‹ˆë‹¤...")
        if world and 'original_settings' in locals():
            world.apply_settings(original_settings)
        if client and actor_list:
            client.apply_batch([carla.command.DestroyActor(x) for x in actor_list])
        cv2.destroyAllWindows()
        print("âœ… ì •ë¦¬ ì™„ë£Œ.")

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="CARLA Multi-Class Drivable Area Dataset Generator")
    parser.add_argument('--host', default='127.0.0.1', help='CARLA ì„œë²„ í˜¸ìŠ¤íŠ¸ IP')
    parser.add_argument('-p', '--port', default=2000, type=int, help='CARLA ì„œë²„ TCP í¬íŠ¸')
    parser.add_argument('--role-name', default='hero', help="Ego ì°¨ëŸ‰ì„ ì‹ë³„í•˜ê¸° ìœ„í•œ role_name")
    args = parser.parse_args()
    try:
        game_loop(args)
    except KeyboardInterrupt:
        pass
